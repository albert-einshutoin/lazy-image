/* tslint:disable */
/* eslint-disable */

/* auto-generated by NAPI-RS */

export interface SanitizeOptions {
  policy?: string
}
export interface FirewallLimitOptions {
  maxPixels?: number
  maxBytes?: number
  timeoutMs?: number
}
export interface Dimensions {
  width: number
  height: number
}
/** Result of applying a preset, contains recommended output settings */
export interface PresetResult {
  /** Recommended output format */
  format: string
  /** Recommended quality (None for PNG) */
  quality?: number
  /** Target width (None if aspect ratio preserved) */
  width?: number
  /** Target height (None if aspect ratio preserved) */
  height?: number
}
export interface BatchResult {
  source: string
  success: boolean
  error?: string
  outputPath?: string
  errorCode?: string
  errorCategory?: ErrorCategory
}
/**
 * Error taxonomy for proper error handling in JavaScript
 *
 * This 4-tier taxonomy enables proper error handling:
 * - UserError: Invalid input, recoverable by user
 * - CodecError: Format/encoding issues
 * - ResourceLimit: Memory/time/dimension limits
 * - InternalBug: Library bugs (should not happen)
 */
export const enum ErrorCategory {
  /** Invalid input, recoverable by user */
  UserError = 0,
  /** Format/encoding issues */
  CodecError = 1,
  /** Memory/time/dimension limits */
  ResourceLimit = 2,
  /** Library bugs (should not happen) */
  InternalBug = 3
}
/** Image metadata returned by inspect() */
export interface ImageMetadata {
  /** Image width in pixels */
  width: number
  /** Image height in pixels */
  height: number
  /** Detected format (jpeg, png, webp, gif, etc.) */
  format?: string
}
/**
 * Inspect image metadata WITHOUT decoding pixels.
 * This reads only the header bytes - extremely fast (<1ms).
 *
 * Use this to check dimensions before processing, or to reject
 * images that are too large without wasting CPU on decoding.
 */
export declare function inspect(buffer: Buffer): ImageMetadata
/**
 * Inspect image metadata from a file path WITHOUT loading into Node.js heap.
 * **Memory-efficient**: Reads directly from filesystem, bypassing V8 entirely.
 * This is the recommended way for server-side metadata inspection.
 */
export declare function inspectFile(path: string): ImageMetadata
/** Get library version */
export declare function version(): string
/** Get supported input formats */
export declare function supportedInputFormats(): Array<string>
/** Get supported output formats */
export declare function supportedOutputFormats(): Array<string>
/** Processing metrics for performance monitoring */
export interface ProcessingMetrics {
  /** Schema version for compatibility negotiation */
  version: string
  /** Decode stage duration in milliseconds */
  decodeMs: number
  /** Ops (transform) stage duration in milliseconds */
  opsMs: number
  /** Encode stage duration in milliseconds */
  encodeMs: number
  /** Total wall-clock duration in milliseconds */
  totalMs: number
  /**
   * Peak memory usage during processing (RSS, bytes, as u32 for NAPI compatibility)
   *
   * **Note**: On Linux/macOS, this uses `ru_maxrss` from `getrusage()`, which represents
   * the cumulative maximum RSS of the entire process, not just this operation.
   * This is a limitation of the `getrusage()` API. For accurate per-operation memory tracking,
   * consider using process-specific memory profiling tools.
   */
  peakRss: number
  /** Total CPU time (user + system) in seconds */
  cpuTime: number
  /** Total processing time (wall clock) in seconds (legacy seconds field) */
  processingTime: number
  /** Input file size in bytes (as u32 for NAPI compatibility, max 4GB) */
  bytesIn: number
  /** Output file size in bytes (as u32 for NAPI compatibility, max 4GB) */
  bytesOut: number
  /** Compression ratio (bytes_out / bytes_in) */
  compressionRatio: number
  /** Detected input format (lowercase: jpeg, png, webp, avif, etc.) */
  formatIn?: string
  /** Output format */
  formatOut: string
  /** True when ICC profile was present and preserved */
  iccPreserved: boolean
  /** True when metadata was stripped (either by default or policy) */
  metadataStripped: boolean
  /** Non-fatal policy rejections (e.g., strict policy forcing metadata strip) */
  policyViolations: Array<string>
  /** Time taken to decode the image (milliseconds) - legacy alias of decode_ms */
  decodeTime: number
  /** Time taken to apply all operations (milliseconds) - legacy alias of ops_ms */
  processTime: number
  /** Time taken to encode the image (milliseconds) - legacy alias of encode_ms */
  encodeTime: number
  /** Peak memory usage during processing (RSS, bytes) - legacy alias of peak_rss */
  memoryPeak: number
  /** Input size legacy alias (bytes_in) */
  inputSize: number
  /** Output size legacy alias (bytes_out) */
  outputSize: number
}
export interface OutputWithMetrics {
  data: Buffer
  metrics: ProcessingMetrics
}
/**
 * The main image processing engine.
 *
 * Usage:
 * ```js
 * const result = await ImageEngine.from(buffer)
 *   .resize(800)
 *   .rotate(90)
 *   .grayscale()
 *   .toBuffer('jpeg', 75);
 * ```
 */
export declare class ImageEngine {
  /**
   * Create engine from a buffer. Decoding is lazy.
   * Extracts ICC profile from the source image if present.
   */
  static from(buffer: Buffer): ImageEngine
  /**
   * Create engine from a file path.
   * **ZERO-COPY MEMORY MAPPING**: Uses mmap to map the file into memory.
   * This enables true zero-copy access - OS pages in only what's needed.
   * This is the recommended way for server-side processing of large images.
   */
  static fromPath(path: string): ImageEngine
  /** Create a clone of this engine (for multi-output scenarios) */
  clone(): ImageEngine
  /**
   * Resize image. Width or height can be null to maintain aspect ratio.
   * When both width and height are provided, `fit` controls behavior:
   * - "inside" (default): maintain aspect ratio and fit within the box
   * - "cover": maintain aspect ratio and crop to fill the box
   * - "fill": ignore aspect ratio and force exact dimensions
   */
  resize(width?: number | undefined | null, height?: number | undefined | null, fit?: string | undefined | null): ImageEngine
  /** Crop a region from the image. */
  crop(x: number, y: number, width: number, height: number): ImageEngine
  /** Rotate by degrees (90, 180, 270 only) */
  rotate(degrees: number): ImageEngine
  /** Flip horizontally */
  flipH(): ImageEngine
  /** Flip vertically */
  flipV(): ImageEngine
  /** Convert to grayscale */
  grayscale(): ImageEngine
  /**
   * Enable or disable EXIF auto-orientation (default: enabled).
   * `true` = apply EXIF Orientation automatically (sharp-compatible)
   * `false` = ignore EXIF Orientation
   */
  autoOrient(enabled: boolean): ImageEngine
  /**
   * Preserve ICC profile in output.
   * Note: Currently only ICC profile is supported. EXIF and XMP metadata are not preserved.
   * By default, all metadata is stripped for security (no GPS leak) and smaller file sizes.
   * Call this method to keep ICC profile when color accuracy is important.
   */
  keepMetadata(): ImageEngine
  /**
   * Enable Image Firewall mode with built-in policies (strict or lenient).
   * Strict mode enforces aggressive limits and rejects dangerous metadata (best for zero-trust inputs).
   * Lenient mode keeps generous limits but still guards against decompression bombs.
   */
  sanitize(options?: SanitizeOptions | undefined | null): ImageEngine
  /**
   * Override Image Firewall limits (maxPixels, maxBytes, timeoutMs).
   * Any field set to 0 disables that particular limit.
   */
  limits(options: FirewallLimitOptions): ImageEngine
  /** Adjust brightness (-100 to 100) */
  brightness(value: number): ImageEngine
  /** Adjust contrast (-100 to 100) */
  contrast(value: number): ImageEngine
  /**
   * Ensure the image is in RGB/RGBA format (pixel format conversion, not color space transformation)
   * Note: This does NOT perform ICC color profile conversion - it only ensures the pixel format.
   * For true color space conversion with ICC profiles, use a dedicated color management library.
   */
  ensureRgb(): ImageEngine
  /**
   * Apply a built-in preset for common use cases.
   *
   * Available presets:
   * - "thumbnail": 150x150, WebP quality 75 (gallery thumbnails)
   * - "avatar": 200x200, WebP quality 80 (profile pictures)
   * - "hero": 1920 width, JPEG quality 85 (hero images, banners)
   * - "social": 1200x630, JPEG quality 80 (OGP/Twitter cards)
   *
   * Returns the preset configuration for use with toBuffer/toFile.
   */
  preset(name: string): PresetResult
  /**
   * Encode to buffer asynchronously.
   * format: "jpeg", "jpg", "png", "webp", "avif"
   * quality: 1-100 (default: JPEG=85, WebP=80, AVIF=60, ignored for PNG)
   * fastMode: If true, uses faster encoding for JPEG (2-4x faster, slightly larger files). Default: false.
   *
   * **Non-destructive**: This method can be called multiple times on the same engine instance.
   * The source data is cloned internally, allowing multiple format outputs.
   */
  toBuffer(format: string, quality?: number | undefined | null, fastMode?: boolean | undefined | null): Promise<Buffer>
  /**
   * Encode to buffer asynchronously with performance metrics.
   * Returns `{ data: Buffer, metrics: ProcessingMetrics }`.
   *
   * **Non-destructive**: This method can be called multiple times on the same engine instance.
   * The source data is cloned internally, allowing multiple format outputs.
   */
  toBufferWithMetrics(format: string, quality?: number | undefined | null, fastMode?: boolean | undefined | null): Promise<OutputWithMetrics>
  /**
   * Encode and write directly to a file asynchronously.
   * **Memory-efficient**: Combined with fromPath(), this enables
   * full file-to-file processing without touching Node.js heap.
   *
   * **Non-destructive**: This method can be called multiple times on the same engine instance.
   * The source data is cloned internally, allowing multiple format outputs.
   *
   * Returns the number of bytes written.
   */
  toFile(path: string, format: string, quality?: number | undefined | null, fastMode?: boolean | undefined | null): Promise<number>
  /**
   * Get image dimensions WITHOUT full decoding.
   * For file paths, reads only the header bytes (extremely fast).
   * For in-memory buffers, uses header-only parsing.
   */
  dimensions(): Dimensions
  /**
   * Check if an ICC color profile was extracted from the source image.
   * Returns the profile size in bytes, or null if no profile exists.
   */
  hasIccProfile(): number | null
  /**
   * Process multiple images in parallel with the same operations.
   *
   * - inputs: Array of input file paths
   * - output_dir: Directory to write processed images
   * - format: Output format ("jpeg", "png", "webp", "avif")
   * - quality: Optional quality (1-100, uses format-specific default if None)
   * - fastMode: Optional fast mode flag (only applies to JPEG, default: false)
   * - concurrency: Optional number of parallel workers:
   *   - 0 or undefined: Auto-detect based on CPU cores and memory limits (smart concurrency)
   *     Detects container memory limits (cgroup v1/v2) and adjusts to prevent OOM kills.
   *     Ideal for serverless/containerized environments with memory constraints.
   *   - 1-1024: Manual override - use specified number of concurrent operations
   */
  processBatch(inputs: Array<string>, outputDir: string, format: string, quality?: number | undefined | null, fastMode?: boolean | undefined | null, concurrency?: number | undefined | null): Promise<BatchResult[]>
}

export interface StreamingOperation {
  op: 'resize' | 'rotate' | 'flipH' | 'flipV' | 'grayscale' | 'autoOrient'
  width?: number | null
  height?: number | null
  fit?: string | null
  degrees?: number
  enabled?: boolean
}

export interface StreamingOptions {
  format?: string
  quality?: number | null
  ops?: StreamingOperation[]
}

export interface StreamingPipeline {
  writable: import('stream').Writable
  readable: import('stream').Readable
}

export function createStreamingPipeline(options?: StreamingOptions): StreamingPipeline
